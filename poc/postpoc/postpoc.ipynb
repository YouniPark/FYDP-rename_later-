{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c14a34b",
   "metadata": {},
   "source": [
    "# Gaze data from LSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pyxdf\n",
    "import numpy as np\n",
    "\n",
    "# Load XDF file \n",
    "xdf_file = 'tobii_test_trial_lsl.xdf'\n",
    "streams, header = pyxdf.load_xdf(xdf_file)\n",
    "\n",
    "# Load Tobii gaze coordinates\n",
    "gaze_stream = None\n",
    "for stream in streams:\n",
    "    if stream['info']['name'][0] == 'Glasses3_Gaze':\n",
    "        gaze_stream = stream\n",
    "        break\n",
    "\n",
    "if gaze_stream is None:\n",
    "    raise ValueError(\"Glasses3_Gaze stream not found in XDF file.\")\n",
    "\n",
    "data = gaze_stream['time_series']\n",
    "timestamps = gaze_stream['time_stamps']\n",
    "\n",
    "# Gaze data: [local_ts, gaze_ts, pixel_x, pixel_y, norm_x, norm_y]\n",
    "local_ts = data[:, 0]\n",
    "gaze_x = data[:, 4]\n",
    "gaze_y = data[:, 5]\n",
    "\n",
    "# Load video\n",
    "video_path = 'scenevideo.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_time = 1.0 / fps \n",
    "cv2.namedWindow('Gaze Overlay', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Gaze Overlay', 960, 540)\n",
    "\n",
    "# Play video with gaze overlay\n",
    "timestamps = timestamps - timestamps[0]\n",
    "gazestartfirst = False\n",
    "if gazestartfirst:\n",
    "    offset = 8.0\n",
    "    valid_indices = timestamps >= offset\n",
    "    timestamps = timestamps[valid_indices] - offset\n",
    "    local_ts = local_ts[valid_indices]\n",
    "    gaze_x = gaze_x[valid_indices]\n",
    "    gaze_y = gaze_y[valid_indices]\n",
    "\n",
    "frame_idx = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    \n",
    "    current_video_time = frame_idx * frame_time\n",
    "    print(current_video_time)\n",
    "\n",
    "    # Find the nearest gaze\n",
    "    gaze_index = np.argmin(np.abs(timestamps - current_video_time))\n",
    "    gx, gy = gaze_x[gaze_index], gaze_y[gaze_index]\n",
    "    lsl_time = local_ts[gaze_index]\n",
    "    \n",
    "    # Convert gaze coordinates to pixel coordinates\n",
    "    h, w, _ = frame.shape\n",
    "    px = int(gx * w)\n",
    "    py = int(gy * h)\n",
    "\n",
    "    # Draw gaze overlay\n",
    "    cv2.circle(frame, (px, py), 20, (0, 0, 255), 2)\n",
    "    \n",
    "    # Display LSL time on frame\n",
    "    cv2.putText(frame, f'LSL Time: {lsl_time:.6f}', (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Gaze Overlay', frame)\n",
    "    if cv2.waitKey(int(frame_time * 1000)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "    # Check if window was closed manually (clicking 'X')\n",
    "    try:\n",
    "        if cv2.getWindowProperty('Gaze Overlay', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    except cv2.error:\n",
    "        # Window was destroyed\n",
    "        break\n",
    "    except cv2.error:\n",
    "        # Window was destroyed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050478c9",
   "metadata": {},
   "source": [
    "# Gaze data from Tobii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load gaze data directly from Tobii\n",
    "file_path = \"gazedata\"\n",
    "\n",
    "timestamps = []\n",
    "gaze2d_x = []\n",
    "gaze2d_y = []\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  \n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            if obj.get(\"type\") == \"gaze\":\n",
    "                gaze2d = obj[\"data\"].get(\"gaze2d\", [])\n",
    "                if gaze2d and len(gaze2d) == 2:\n",
    "                    timestamps.append(obj[\"timestamp\"])\n",
    "                    gaze2d_x.append(gaze2d[0])\n",
    "                    gaze2d_y.append(gaze2d[1])\n",
    "                else:\n",
    "                    continue\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Skipping line due to JSON error:\", e)\n",
    "\n",
    "timestamps = np.array(timestamps, dtype=float)\n",
    "gaze2d_x = np.array(gaze2d_x, dtype=float)\n",
    "gaze2d_y = np.array(gaze2d_y, dtype=float)\n",
    "\n",
    "# Load video\n",
    "video_path = 'scenevideo.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_time = 1.0 / fps \n",
    "cv2.namedWindow('Gaze Overlay', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Gaze Overlay', 960, 540)\n",
    "\n",
    "# Play video with gaze overlay\n",
    "frame_idx = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    \n",
    "    current_video_time = frame_idx * frame_time\n",
    "\n",
    "    # Find the nearest gaze\n",
    "    gaze_index = np.argmin(np.abs(timestamps - current_video_time))\n",
    "    gx, gy = gaze2d_x[gaze_index], gaze2d_y[gaze_index]\n",
    "    \n",
    "    # Convert gaze coordinates to pixel coordinates\n",
    "    h, w, _ = frame.shape\n",
    "    px = int(gx * w)\n",
    "    py = int(gy * h)\n",
    "\n",
    "    # Draw gaze overlay\n",
    "    cv2.circle(frame, (px, py), 20, (0, 0, 255), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Gaze Overlay', frame)\n",
    "    if cv2.waitKey(int(frame_time * 1000)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "    # Check if window was closed manually (clicking 'X')\n",
    "    try:\n",
    "        if cv2.getWindowProperty('Gaze Overlay', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    except cv2.error:\n",
    "        # Window was destroyed\n",
    "        break\n",
    "    except cv2.error:\n",
    "        # Window was destroyed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27377ef",
   "metadata": {},
   "source": [
    "# Gaze Data LSL and Tobii Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784f838",
   "metadata": {},
   "source": [
    "Load data from LSL file (.xdf) AND Tobii file (.gazedata)\n",
    "Load video\n",
    "Display eye tracking gaze for both LSL file and Tobii file simultaneously.\n",
    "\n",
    "Note: To sync up with the video and Tobii gaze data, LSL file .xdf should begin at LSL timestamp 232200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pyxdf\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "# Load XDF file for LSL gaze data\n",
    "xdf_file = 'tobii_test_trial_lsl.xdf'\n",
    "streams, header = pyxdf.load_xdf(xdf_file)\n",
    "\n",
    "gaze_stream = None\n",
    "for stream in streams:\n",
    "    if stream['info']['name'][0] == 'Glasses3_Gaze':\n",
    "        gaze_stream = stream\n",
    "        break\n",
    "\n",
    "if gaze_stream is None:\n",
    "    raise ValueError(\"Glasses3_Gaze stream not found in XDF file.\")\n",
    "\n",
    "lsl_data = gaze_stream['time_series']\n",
    "\n",
    "# LSL Gaze data: [local_ts, gaze_ts, pixel_x, pixel_y, norm_x, norm_y]\n",
    "lsl_local_ts = lsl_data[:, 0]\n",
    "lsl_gaze_x = lsl_data[:, 4]\n",
    "lsl_gaze_y = lsl_data[:, 5]\n",
    "\n",
    "# Load Tobii gaze data\n",
    "file_path = \"gazedata\"\n",
    "tobii_timestamps = []\n",
    "tobii_gaze_x = []\n",
    "tobii_gaze_y = []\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  \n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            if obj.get(\"type\") == \"gaze\":\n",
    "                gaze2d = obj[\"data\"].get(\"gaze2d\", [])\n",
    "                if gaze2d and len(gaze2d) == 2:\n",
    "                    tobii_timestamps.append(obj[\"timestamp\"])\n",
    "                    tobii_gaze_x.append(gaze2d[0])\n",
    "                    tobii_gaze_y.append(gaze2d[1])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Skipping line due to JSON error:\", e)\n",
    "\n",
    "tobii_timestamps = np.array(tobii_timestamps, dtype=float)\n",
    "tobii_gaze_x = np.array(tobii_gaze_x, dtype=float)\n",
    "tobii_gaze_y = np.array(tobii_gaze_y, dtype=float)\n",
    "\n",
    "# Load video\n",
    "video_path = 'scenevideo.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_time = 1.0 / fps\n",
    "\n",
    "# Sync LSL data (start at LSL timestamp 232200)\n",
    "lsl_sync_offset = 232200.0\n",
    "\n",
    "# Setup display queue and control flags\n",
    "display_queue = Queue(maxsize=2)\n",
    "quit_flag = False\n",
    "window_name = 'LSL vs Tobii Comparison'\n",
    "\n",
    "def display_thread_worker():\n",
    "    \"\"\"Worker thread that handles OpenCV display operations.\"\"\"\n",
    "    global quit_flag\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)\n",
    "    cv2.resizeWindow(window_name, 960, 540)\n",
    "    \n",
    "    while not quit_flag:\n",
    "        try:\n",
    "            # Get the latest frame from the queue (non-blocking)\n",
    "            if not display_queue.empty():\n",
    "                frame = display_queue.get_nowait()\n",
    "                cv2.imshow(window_name, frame)\n",
    "            \n",
    "            # Check for key presses and window events\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                quit_flag = True\n",
    "                break\n",
    "            \n",
    "            # Check if window was closed manually\n",
    "            try:\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    quit_flag = True\n",
    "                    break\n",
    "            except cv2.error:\n",
    "                quit_flag = True\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            if not quit_flag:\n",
    "                print(f\"Display thread error: {e}\")\n",
    "            break\n",
    "    \n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "# Start display thread\n",
    "display_thread = Thread(target=display_thread_worker, daemon=True)\n",
    "display_thread.start()\n",
    "print(\"Display thread started - video playback will continue even when dragging the window\")\n",
    "\n",
    "# Main processing loop with proper frame timing\n",
    "frame_idx = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while not quit_flag:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    \n",
    "    current_video_time = frame_idx * frame_time\n",
    "    current_lsl_time = lsl_sync_offset + current_video_time\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "    # Find nearest LSL gaze using lsl_local_ts\n",
    "    lsl_index = np.argmin(np.abs(lsl_local_ts - current_lsl_time))\n",
    "    lsl_gx, lsl_gy = lsl_gaze_x[lsl_index], lsl_gaze_y[lsl_index]\n",
    "    lsl_time = lsl_local_ts[lsl_index]\n",
    "    lsl_px = int(lsl_gx * w)\n",
    "    lsl_py = int(lsl_gy * h)\n",
    "    \n",
    "    # Find nearest Tobii gaze\n",
    "    tobii_index = np.argmin(np.abs(tobii_timestamps - current_video_time))\n",
    "    tobii_gx, tobii_gy = tobii_gaze_x[tobii_index], tobii_gaze_y[tobii_index]\n",
    "    tobii_time = tobii_timestamps[tobii_index]\n",
    "    tobii_px = int(tobii_gx * w)\n",
    "    tobii_py = int(tobii_gy * h)\n",
    "    \n",
    "    # Draw both gaze overlays on a copy of the frame\n",
    "    display_frame = frame.copy()\n",
    "    cv2.circle(display_frame, (lsl_px, lsl_py), 20, (0, 0, 255), 2)  # Red for LSL\n",
    "    cv2.circle(display_frame, (tobii_px, tobii_py), 20, (255, 0, 0), 2)  # Blue for Tobii\n",
    "    \n",
    "    # Add labels\n",
    "    cv2.putText(display_frame, 'LSL (Red)', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.putText(display_frame, f'LSL Time: {lsl_time:.2f}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    cv2.putText(display_frame, f'LSL Gaze: ({lsl_gx:.3f}, {lsl_gy:.3f})', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    cv2.putText(display_frame, 'Tobii (Blue)', (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    cv2.putText(display_frame, f'Tobii Time: {tobii_time:.2f}', (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    cv2.putText(display_frame, f'Tobii Gaze: ({tobii_gx:.3f}, {tobii_gy:.3f})', (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    \n",
    "    # Push to display queue (drop old frames if full)\n",
    "    if display_queue.full():\n",
    "        try:\n",
    "            display_queue.get_nowait()\n",
    "        except:\n",
    "            pass\n",
    "    display_queue.put_nowait(display_frame)\n",
    "    \n",
    "    frame_idx += 1\n",
    "    \n",
    "    # Maintain proper playback speed\n",
    "    expected_time = start_time + (frame_idx * frame_time)\n",
    "    current_time = time.time()\n",
    "    sleep_time = expected_time - current_time\n",
    "    if sleep_time > 0:\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "quit_flag = True\n",
    "display_thread.join(timeout=2.0)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video playback complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_postpoc (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
